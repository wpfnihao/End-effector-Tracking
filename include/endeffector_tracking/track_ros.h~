#include <ros/ros.h>

#include <cv_bridge/cv_bridge.h>

//OpenCV headers
#include <opencv2/core/core.hpp>
#include <opencv2/imgproc/imgproc.hpp>
// for Kalman filter
#include <opencv2/video/tracking.hpp>

#include <sensor_msgs/image_encodings.h>
#include <image_transport/image_transport.h>

//visp headers
//the vpMbTracker class, used to get the initial pose
#include <visp/vpMbEdgeTracker.h>
//the vpPose classs, used to calc pose from features
//the vpHomogeneousMatrix.h is also included in this head file
#include <visp/vpPose.h>
#include <visp/vpImage.h>
#include <visp/vpCameraParameters.h>

#include <conversions/image.h>

// stl headers
#include <vector>
#include <iostream>

class CEndeffectorTracking
{
public:
	//tracking status
	enum tracking_status
	{
		TRACKING,
		LOST,
		INITIAL
	};

	// lines to describe the model
	typedef std::vector<cv::Point3f> modelLine;

	// projected lines to describe the model
	typedef std::vector<cv::Point2f> prjLine;

//member variable
private:
	ros::NodeHandle n;
	image_transport::Subscriber subCam;

	// several config file obtained from the launch file
	std::string camera_topic;
	std::string config_file;
	std::string model_name;
	std::string init_file;

	// current frame
	cv::Mat curImg;

	// rows and cols
	int rows, cols;

	// the processed ver. of current frame to display the tracking rst
	cv::Mat processedImg;

	// lines generated by hough transform
	std::vector<cv::Vec4i> lines;

	image_transport::Publisher imgPub;

	// current tracking status
	tracking_status status;

	// the current pose
	vpHomogeneousMatrix cMo;
	// the pose vector corresponding to the pose matrix
	// tx, ty, tz, thetaux, thetauy, thetauz
	vpPoseVector poseVector;

	// predicted pose
	vpPoseVector p_Pose;

	// predicted cMo
	vpHomogeneousMatrix p_cMo;

	// the camera currently used
	vpCameraParameters cam;

	// initial points defined in the .init file
	std::vector<cv::Point3f> initP;

	//the cube
	//cube corners
	std::vector<cv::Point3f> corners;

	//cube lines
	std::vector<modelLine> model;

	// projected cube lines by the current pose (a.k.a. cMo)
	std::vector<prjLine> prjModel;

	// projected corners
	std::vector<cv::Point2f> prjCorners;

	// current window for hough
	// p1 let up
	// p2 right bottom
	// window: x1, y1, x2, y2
	int window[4];

	// Kalman filter, tracking the pose (cMo)
	// cMo is a 4*4 matrix, however the state has 6 measurements and 6 velocities of the measurement
	cv::KalmanFilter KF;

public:
	// constructor
	// ros is inited in this function
	CEndeffectorTracking(int argc, char **argv);
			
	//member function 
	//the tracking callback function, which actually does the tracking procedure
	void trackCallback(const sensor_msgs::ImageConstPtr& srcImg);	

	//convert from the ros image message to a CvImage
	void msg2mat(const sensor_msgs::ImageConstPtr& srcImg, cv::Mat& curImg_);	
	//use hough transform to detect lines in a given window
	void houghLineDetection(const int* win);

	// when initialize the tracker or the tracker lost the target
	// call this function to (re)initialize it
	void initializeTracker(const sensor_msgs::ImageConstPtr& srcImg);
	// tracking is done here
	void track(const sensor_msgs::ImageConstPtr& srcImg);

	// parse the .init file, and get the init points
	void getInitPoints(void);

	// I still don't know how to read the model from the wrl or cad or cao file
	// However, it is sufficient to get the cube from the init file
	// if in the future, more complex model is tracked, I should reimplement this function
	void initCornersLines(void);


	// project the model into the image using the provided  pose (usually the predicted one or the measured one)
	void projectModel(const vpHomogeneousMatrix& cMo_);

	// initialize the Kalman filter, such as the measurement matrix etc.
	void initKalman(void);

	// generate a window for hough transform
	void genTrackingWindow(void);
protected:

};
